# -*- coding: utf-8 -*-
"""final_cv_codes.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1myq1htzfBHSOKtziIhJ7l3-cjn45R8cd
"""

pip install opencv-python

import os
print(os.getcwd())  # shows where Python is looking for files

"""Experiment 1"""

import cv2
from google.colab.patches import cv2_imshow

img = cv2.imread('/content/sample.jpg')

if img is None:
    print("Error: Image not found or could not be loaded. Please ensure 'istockphoto-517188688-1024x1024.jpg' is in '/content/'.")
else:
    cv2_imshow(img)
    print("Image Dimensions:", img.shape)
    cv2.waitKey(0)
    cv2.destroyAllWindows()

"""Experiment 2"""

import cv2
from google.colab.patches import cv2_imshow

img = cv2.imread('/content/sample1.jpg')
gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

cv2_imshow(img)
cv2_imshow(gray)
cv2.waitKey(0)
cv2.destroyAllWindows()

"""Experiment 3"""

import cv2
from google.colab.patches import cv2_imshow

img = cv2.imread('/content/sample.jpg')
resized = cv2.resize(img, (400, 300))

cv2_imshow(img)
cv2_imshow(resized)
cv2.waitKey(0)
cv2.destroyAllWindows()

"""Experiment 4"""

import cv2
import numpy as np
from google.colab.patches import cv2_imshow

img = cv2.imread('/content/sample.jpg')

(h, w) = img.shape[:2]
center = (w // 2, h // 2)
M = cv2.getRotationMatrix2D(center, 45, 1.0)
rotated = cv2.warpAffine(img, M, (w, h))

pts1 = np.float32([[50,50], [200,50], [50,200]])
pts2 = np.float32([[10,100], [200,50], [100,250]])
M_affine = cv2.getAffineTransform(pts1, pts2)
affine_transformed = cv2.warpAffine(img, M_affine, (w, h))

cv2_imshow(rotated)
cv2_imshow(affine_transformed)
cv2.waitKey(0)
cv2.destroyAllWindows()

"""Experiment 5"""

import cv2
from google.colab.patches import cv2_imshow

img = cv2.imread('/content/sample.jpg')
gaussian_blur = cv2.GaussianBlur(img, (5, 5), 0)

cv2_imshow(img)
cv2_imshow(gaussian_blur)
cv2.waitKey(0)
cv2.destroyAllWindows()

"""Experiment 6"""

import cv2
from google.colab.patches import cv2_imshow

img = cv2.imread('/content/sample1.jpg', 0)
blur = cv2.GaussianBlur(img, (5,5), 0)
edges = cv2.Canny(blur, 100, 200)

cv2_imshow(img)
cv2_imshow(edges)
cv2.waitKey(0)
cv2.destroyAllWindows()

"""Experiment 7"""

import cv2
from google.colab.patches import cv2_imshow

img = cv2.imread('/content/sample1.jpg', 0)

_, thresh_global = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY)
thresh_adaptive = cv2.adaptiveThreshold(img, 255,
                                        cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
                                        cv2.THRESH_BINARY, 11, 2)

cv2_imshow(thresh_global)
cv2_imshow(thresh_adaptive)
cv2.waitKey(0)
cv2.destroyAllWindows()

"""Experiment 8"""

import cv2
from google.colab.patches import cv2_imshow

img = cv2.imread('/content/sample.jpg')
flip_horizontal = cv2.flip(img, 1)
flip_vertical = cv2.flip(img, 0)
flip_both = cv2.flip(img, -1)

cv2_imshow(flip_horizontal)
cv2_imshow(flip_vertical)
cv2_imshow(flip_both)
cv2.waitKey(0)
cv2.destroyAllWindows()

"""Experiment 9"""

import cv2
import numpy as np
from google.colab.patches import cv2_imshow

img = np.zeros((400,400,3), dtype='uint8')

cv2.line(img, (50,50), (350,50), (255,0,0), 3)
cv2.rectangle(img, (100,100), (300,300), (0,255,0), 3)
cv2.circle(img, (200,200), 50, (0,0,255), -1)

cv2_imshow(img)
cv2.waitKey(0)
cv2.destroyAllWindows()

"""Experiment 10"""

import cv2
import numpy as np
from google.colab.patches import cv2_imshow

img = np.zeros((400,400,3), dtype='uint8')

cv2.circle(img, (200,100), 30, (0,255,0), -1)
cv2.putText(img, 'Object A', (150,180), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255,255,255), 2)
cv2.putText(img, 'Detected', (140,220), cv2.FONT_HERSHEY_DUPLEX, 0.8, (255,0,0), 2)

cv2_imshow(img)
cv2.waitKey(0)
cv2.destroyAllWindows()

"""Experiment 11"""

import cv2

img = cv2.imread('/content/sample.jpg')

# Save in different formats
cv2.imwrite('/content/sample_output.jpg', img, [int(cv2.IMWRITE_JPEG_QUALITY), 90])
cv2.imwrite('/content/sample_output.png', img, [int(cv2.IMWRITE_PNG_COMPRESSION), 3])

"""Experiment 12"""

!wget https://github.com/opencv/opencv/raw/master/data/haarcascades/haarcascade_frontalface_default.xml -O /content/haarcascade_frontalface_default.xml

import cv2
from google.colab.patches import cv2_imshow

face_cascade = cv2.CascadeClassifier('/content/haarcascade_frontalface_default.xml')
img = cv2.imread('/content/sample.jpg')
gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

faces = face_cascade.detectMultiScale(gray, 1.3, 5)
for (x, y, w, h) in faces:
    cv2.rectangle(img, (x, y), (x+w, y+h), (255, 0, 0), 2)

cv2_imshow(img)
cv2.waitKey(0)
cv2.destroyAllWindows()

"""Experiment 13"""

import cv2
from google.colab.patches import cv2_imshow

img = cv2.imread('/content/sample1.jpg')
negative = 255 - img

cv2_imshow(img)
cv2_imshow(negative)
cv2.waitKey(0)
cv2.destroyAllWindows()

"""Experiment 14"""

import cv2
import numpy as np
from google.colab.patches import cv2_imshow

img = cv2.imread('/content/images.jpeg', 0)
c = 255 / np.log(1 + np.max(img))
log_transformed = c * (np.log(1 + img))
log_transformed = np.array(log_transformed, dtype=np.uint8)

cv2_imshow(img)
cv2_imshow(log_transformed)
cv2.waitKey(0)
cv2.destroyAllWindows()

"""Experiment 15"""

import cv2
import numpy as np
from google.colab.patches import cv2_imshow

img = cv2.imread('/content/images.jpeg')
gamma = 0.5  # adjust brightness
gamma_corrected = np.array(255 * (img / 255) ** gamma, dtype='uint8')

cv2_imshow(img)
cv2_imshow(gamma_corrected)
cv2.waitKey(0)
cv2.destroyAllWindows()

"""Experiment 16"""

import cv2
import numpy as np
from google.colab.patches import cv2_imshow
import matplotlib.pyplot as plt

img = cv2.imread('/content/low_contrast.jpeg', 0)
equalized_img = cv2.equalizeHist(img)

cv2_imshow(img)
cv2_imshow(equalized_img)

cv2.imwrite('/content/equalized_output.jpg', equalized_img)
print("Histogram equalization completed successfully.")

plt.figure(figsize=(10,4))
plt.subplot(1,2,1)
plt.hist(img.ravel(), 256, [0,256])
plt.title('Original Histogram')
plt.subplot(1,2,2)
plt.hist(equalized_img.ravel(), 256, [0,256])
plt.title('Equalized Histogram')
plt.show()

"""Experiment 17"""

import cv2
import numpy as np
from google.colab.patches import cv2_imshow

img = cv2.imread('/content/low_contrast.jpeg', 0)
r_min, r_max = np.min(img), np.max(img)
stretched = ((img - r_min) / (r_max - r_min)) * 255
stretched = stretched.astype('uint8')

cv2_imshow(img)
cv2_imshow(stretched)
cv2.waitKey(0)
cv2.destroyAllWindows()

"""Experiemnt 18"""

import cv2
from google.colab.patches import cv2_imshow

img = cv2.imread('/content/sample.jpg')
mean_filtered = cv2.blur(img, (5,5))

cv2_imshow(img)
cv2_imshow(mean_filtered)
cv2.waitKey(0)
cv2.destroyAllWindows()

"""Experiment 19"""

import cv2
import numpy as np
from google.colab.patches import cv2_imshow

img = cv2.imread('/content/sample.jpg')

laplacian = cv2.Laplacian(img, cv2.CV_64F)
sharpened = cv2.convertScaleAbs(img - 0.5 * laplacian)

cv2_imshow(img)
cv2_imshow(sharpened)
cv2.waitKey(0)
cv2.destroyAllWindows()

"""Experiment 20"""

import cv2
import numpy as np
from google.colab.patches import cv2_imshow

img = cv2.imread('/content/sample.jpg', 0)
sobelx = cv2.Sobel(img, cv2.CV_64F, 1, 0, ksize=3)
sobely = cv2.Sobel(img, cv2.CV_64F, 0, 1, ksize=3)
sobel_mag = cv2.magnitude(sobelx, sobely)
sobel_mag = np.uint8(np.absolute(sobel_mag))

cv2_imshow(img)
cv2_imshow(sobel_mag)
cv2.waitKey(0)
cv2.destroyAllWindows()

"""Experiment 21"""

import cv2
import numpy as np
from google.colab.patches import cv2_imshow # Import cv2_imshow for Colab compatibility

img = cv2.imread('/content/sample.jpg')
blur = cv2.GaussianBlur(img, (5,5), 0)
unsharp = cv2.addWeighted(img, 1.2, blur, -0.1, 0)

cv2_imshow(img)
cv2_imshow(unsharp)
cv2.waitKey(0)
cv2.destroyAllWindows()

"""Experiment 22"""

import cv2
from google.colab.patches import cv2_imshow

img = cv2.imread('/content/low_contrast.jpeg', 0)
bit_planes = [(img & (1 << i)) >> i for i in range(8)]

for i in range(8):
    cv2_imshow(bit_planes[i] * 255)
cv2.waitKey(0)
cv2.destroyAllWindows()

"""Experiment 23"""

from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score
import numpy as np

X = np.random.rand(100, 50)  # example dataset
y = np.random.randint(0, 2, 100)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
model = SVC(kernel='linear')
model.fit(X_train, y_train)
pred = model.predict(X_test)

print("Accuracy:", accuracy_score(y_test, pred))

"""Experiemt 24"""

import cv2
import numpy as np
from google.colab.patches import cv2_imshow

# Step 1: Load YOLOv3 model (make sure these files are in your working directory)
net = cv2.dnn.readNet('/content/yolov3.weights', '/content/yolov3.cfg')

# Step 2: Load COCO class labels
with open('/content/coco.names', 'r') as f:
    classes = [line.strip() for line in f.readlines()]

# Step 3: Load the input image
img = cv2.imread('/content/images.jpeg')
height, width = img.shape[:2]

# Step 4: Prepare the image as blob and set as network input
blob = cv2.dnn.blobFromImage(img, 1/255.0, (416, 416), swapRB=True, crop=False)
net.setInput(blob)

# Step 5: Get output layer names
layer_names = net.getLayerNames()
output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]

# Step 6: Perform forward pass (object detection)
outs = net.forward(output_layers)

# Step 7: Initialize lists for detection data
class_ids = []
confidences = []
boxes = []

# Step 8: Process each detection output
for out in outs:
    for detection in out:
        scores = detection[5:]
        class_id = np.argmax(scores)
        confidence = scores[class_id]
        if confidence > 0.5:
            # Object detected
            center_x = int(detection[0] * width)
            center_y = int(detection[1] * height)
            w = int(detection[2] * width)
            h = int(detection[3] * height)
            x = int(center_x - w / 2)
            y = int(center_y - h / 2)
            boxes.append([x, y, w, h])
            confidences.append(float(confidence))
            class_ids.append(class_id)

# Step 9: Apply Non-Maximum Suppression to remove duplicates
indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)

# Step 10: Draw bounding boxes and labels
font = cv2.FONT_HERSHEY_SIMPLEX
colors = np.random.uniform(0, 255, size=(len(classes), 3))

for i in range(len(boxes)):
    if i in indexes:
        x, y, w, h = boxes[i]
        label = str(classes[class_ids[i]])
        confidence = round(confidences[i], 2)
        color = colors[class_ids[i]]
        cv2.rectangle(img, (x, y), (x + w, y + h), color, 2)
        cv2.putText(img, f'{label} {confidence}', (x, y - 10), font, 0.6, color, 2)

# Step 11: Display the output
cv2_imshow(img)
cv2.imwrite('/content/images.jpeg', img)
cv2.waitKey(0)
cv2.destroyAllWindows()
print("✅ Object detection completed and image saved as 'object_detection_output.jpg'")

"""Experiment 25"""

!pip install face_recognition



import cv2
import os
from google.colab.patches import cv2_imshow
import numpy as np

# Step 1: Load Haar Cascade for face detection
face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + "haarcascade_frontalface_default.xml")

# Step 2: Prepare training data
train_dir = '/content/train_faces/train_faces' # Corrected path
recognizer = cv2.face.LBPHFaceRecognizer_create()

faces = []
labels = []
label_map = {}

label_id = 0
for person in os.listdir(train_dir):
    person_dir = os.path.join(train_dir, person)
    if not os.path.isdir(person_dir):
        continue
    label_map[label_id] = person
    for img_file in os.listdir(person_dir):
        img_path = os.path.join(person_dir, img_file)
        img = cv2.imread(img_path, 0)
        if img is None:
            print(f"Warning: Could not read image {img_path}. Skipping.")
            continue
        faces_detected = face_cascade.detectMultiScale(img, 1.3, 5)
        for (x, y, w, h) in faces_detected:
            faces.append(img[y:y+h, x:x+w])
            labels.append(label_id)
    label_id += 1

# Step 3: Train recognizer
recognizer.train(faces, np.array(labels))

# Step 4: Test on a new image
test_img = cv2.imread('/content/train_faces/train_faces/Baby/known_1.jpg', 0)
if test_img is None:
    print("Error: Could not read test image /content/test_face.jpg")
else:
    faces_test = face_cascade.detectMultiScale(test_img, 1.3, 5)
    for (x, y, w, h) in faces_test:
        face_roi = test_img[y:y+h, x:x+w]
        label, confidence = recognizer.predict(face_roi)
        name = label_map.get(label, "Unknown") # Handle unknown labels
        color = (0, 255, 0) if confidence < 80 else (0, 0, 255)
        cv2.rectangle(test_img, (x, y), (x + w, y + h), color, 2)
        cv2.putText(test_img, f"{name} ({int(confidence)})", (x, y - 10),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)

    cv2_imshow(test_img)
    print("✅ Face recognition & verification completed successfully.")

"""Experiment No 26"""

import cv2
import numpy as np
from google.colab.patches import cv2_imshow

img = cv2.imread('/content/x ray sample.jpg', 0)
blurred = cv2.GaussianBlur(img, (5, 5), 0)
edges = cv2.Canny(blurred, 50, 150)
_, thresh = cv2.threshold(blurred, 120, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)
contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

output = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)
cv2.drawContours(output, contours, -1, (0, 255, 0), 2)
cv2_imshow(edges)
cv2_imshow(thresh)
cv2_imshow(output)
cv2.waitKey(0)
cv2.destroyAllWindows()
print("✅ Medical image processed successfully for CAD visualization.")

"""Experiment 27"""

import cv2
import numpy as np
from google.colab.patches import cv2_imshow

img = cv2.imread('/content/0_b5ptHu0y7wUeMddy.jpg')
gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
blur = cv2.GaussianBlur(gray, (5,5), 0)
edges = cv2.Canny(blur, 50, 150)
lines = cv2.HoughLinesP(edges, 1, np.pi/180, 100, minLineLength=100, maxLineGap=50)

if lines is not None:
    for line in lines:
        x1, y1, x2, y2 = line[0]
        cv2.line(img, (x1, y1), (x2, y2), (0, 255, 0), 3)

sign = cv2.imread('/content/traffic_sign.png')
template = cv2.imread('/content/stop_template.png', 0)
sign_gray = cv2.cvtColor(sign, cv2.COLOR_BGR2GRAY)
res = cv2.matchTemplate(sign_gray, template, cv2.TM_CCOEFF_NORMED)
threshold = 0.7
loc = np.where(res >= threshold)

for pt in zip(*loc[::-1]):
    cv2.rectangle(sign, pt, (pt[0] + template.shape[1], pt[1] + template.shape[0]), (0, 0, 0), 3)
    cv2.putText(sign, "STOP SIGN DETECTED", (pt[0], pt[1]-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0,0,0), 2)

cv2_imshow(img)
cv2_imshow(sign)
cv2.waitKey(0)
cv2.destroyAllWindows()

"""Experiment 28"""

from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input, decode_predictions
from tensorflow.keras.preprocessing import image
from PIL import Image
import numpy as np

model = InceptionV3(weights='imagenet')
img = Image.open('/content/images.jpeg').resize((299, 299))
x = image.img_to_array(img)
x = np.expand_dims(x, axis=0)
x = preprocess_input(x)
preds = model.predict(x)
caption = decode_predictions(preds, top=1)[0][0][1]
print("Generated Caption:", caption)

"""Experiment 29"""

!pip install mediapipe opencv-python

import cv2
import mediapipe as mp
from google.colab.patches import cv2_imshow

mp_hands = mp.solutions.hands
mp_drawing = mp.solutions.drawing_utils
hands = mp_hands.Hands(static_image_mode=True, max_num_hands=1, min_detection_confidence=0.5)

img = cv2.imread('/content/gesture.jpg')
img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
results = hands.process(img_rgb)

if results.multi_hand_landmarks:
    for hand_landmarks in results.multi_hand_landmarks:
        mp_drawing.draw_landmarks(img, hand_landmarks, mp_hands.HAND_CONNECTIONS)

cv2_imshow(img)
cv2.waitKey(0)
cv2.destroyAllWindows()

import cv2
from google.colab.patches import cv2_imshow

img = cv2.imread('/content/x ray sample.jpg', 0)
blur = cv2.GaussianBlur(img, (5,5), 0)
edges = cv2.Canny(blur, 50, 150)

cv2_imshow(img)
cv2_imshow(edges)